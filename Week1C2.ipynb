{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Week1C2.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyM+IF+hK5TJ/HExQGT9aWks",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/thelc127/NLP-Specialization/blob/master/Week1C2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "atdCoK0KEk3O"
      },
      "source": [
        "# Visualizing tweets and the Logistic Regression model\n",
        "# Steps:\n",
        "\n",
        "#     #Plot tweets in a scatter plot using their positive and negative sums.\n",
        "#     Plot the output of the logistic regression model in the same plot as a solid line\n"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gQ2cDdDSE1XH"
      },
      "source": [
        "import nltk\n",
        "from os import getcwd\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from nltk.corpus import twitter_samples\n",
        "from sample_data.utils import process_tweet, build_freqs"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B8OOoYs0Fk-O",
        "outputId": "039a921b-cb0f-4f30-e00c-f5f207c1e511",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 111
        }
      },
      "source": [
        "# download the stopwords for the process_tweet function\n",
        "nltk.download('stopwords')\n",
        "\n",
        "nltk.download('twitter_samples')"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package twitter_samples to /root/nltk_data...\n",
            "[nltk_data]   Package twitter_samples is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fqhL0LndjPAW",
        "outputId": "ec10cb0a-c5c8-4c79-c9a0-54522072927f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "#Load the NLTK sample dataset\n",
        "# select the lists of positive and negative tweets\n",
        "all_positive_tweets = twitter_samples.strings('positive_tweets.json')\n",
        "all_negative_tweets = twitter_samples.strings('negative_tweets.json')\n",
        "\n",
        "# concatenate the lists, 1st part is the positive tweets followed by the negative\n",
        "tweets = all_positive_tweets + all_negative_tweets\n",
        "\n",
        "# let's see how many tweets we have\n",
        "print(\"Number of tweets: \", len(tweets))"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of tweets:  10000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OZwZ_-IqjgMq"
      },
      "source": [
        "# make a numpy array representing labels of the tweets\n",
        "labels = np.append(np.ones((len(all_positive_tweets))), np.zeros((len(all_negative_tweets))))"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E1Bci2fSjuzU"
      },
      "source": [
        "# Dictionaries\n",
        "\n",
        "# In Python, a dictionary is a mutable and indexed collection. It stores items as key-value pairs and uses hash tables underneath to allow practically constant time lookups. In NLP, dictionaries are essential because it enables fast retrieval of items or containment checks even with thousands of entries in the collection.\n",
        "# Definition\n",
        "\n",
        "# A dictionary in Python is declared using curly brackets. Look at the next example:\n",
        "\n",
        "dictionary = {'key1': 1, 'key2': 2}\n"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "onYbRM70j7IY",
        "outputId": "54e1d072-c8e9-43dd-d83c-264019de12ac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "# Add a new entry\n",
        "dictionary['key3'] = -5\n",
        "\n",
        "# Overwrite the value of key1\n",
        "dictionary['key1'] = 0\n",
        "\n",
        "print(dictionary)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'key1': 0, 'key2': 2, 'key3': -5}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z7Bhey0NkBIs",
        "outputId": "effa0f94-1fbd-44f9-8a6e-a78c9c6a48bb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "# Accessing values and lookup keys\n",
        "\n",
        "# Performing dictionary lookups and retrieval are common tasks in NLP. There are two ways to do this:\n",
        "\n",
        "#     Using square bracket notation: This form is allowed if the lookup key is in the dictionary. It produces an error otherwise.\n",
        "#     Using the get() method: This allows us to set a default value if the dictionary key does not exist.\n",
        "\n",
        "# Let us see these in action:\n",
        "# Square bracket lookup when the key exist\n",
        "print(dictionary['key2'])\n"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oNQP09r3kWl7"
      },
      "source": [
        "# The output of this line is intended to produce a KeyError\n",
        "# print(dictionary['key8'])"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OTa34fIvkZJe",
        "outputId": "45d6ef7a-abd1-4232-a557-335119856886",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "\n",
        "# This prints a value\n",
        "if 'key1' in dictionary:\n",
        "    print(\"item found: \", dictionary['key1'])\n",
        "else:\n",
        "    print('key1 is not defined')\n",
        "\n",
        "# Same as what you get with get\n",
        "print(\"item found: \", dictionary.get('key1', -1))"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "item found:  0\n",
            "item found:  0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MVcqwxOQkj3v",
        "outputId": "e7ca65aa-1d7b-4959-9588-e49a3604a220",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "# This prints a message because the key is not found\n",
        "if 'key7' in dictionary:\n",
        "    print(dictionary['key7'])\n",
        "else:\n",
        "    print('key does not exist!')\n",
        "\n",
        "# This prints -1 because the key is not found and we set the default to -1\n",
        "print(dictionary.get('key7', -1))"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "key does not exist!\n",
            "-1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DuirHDwZkq33"
      },
      "source": [
        "# Word frequency dictionary\n",
        "\n",
        "# Now that we know the building blocks, let's finally take a look at the build_freqs() function in utils.py. This is the function that creates the dictionary containing the word counts from each corpus.\n"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nJ4eRqd1oR10"
      },
      "source": [
        ""
      ],
      "execution_count": 35,
      "outputs": []
    }
  ]
}